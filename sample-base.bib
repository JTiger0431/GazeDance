%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "Gerry Murray",
%%%     version         = "1.2",
%%%     date            = "2 April 2012",
%%%     filename        = "acmsmall-sample-bibfile.bib",
%%%     address         = "ACM, NY",
%%%     email           = "murray at hq.acm.org",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "ACM Reference Format, bibliography, citation, references",
%%%     supported       = "yes",
%%%     docstring       = "This BibTeX database file contains 'bibdata' entries
%%%                        that 'match' the examples provided in the Specifications Document
%%%                        AND, also, 'legacy'-type bibs. It should assist authors in
%%%                        choosing the 'correct' at-bibtype and necessary bib-fields
%%%                        so as to obtain the appropriate ACM Reference Format output.
%%%                        It also contains many 'Standard Abbreviations'. "
%%%  }
%%% ====================================================================

% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@inproceedings{krafka2016eye,
  title={Eye tracking for everyone},
  author={Krafka, Kyle and Khosla, Aditya and Kellnhofer, Petr and Kannan, Harini and Bhandarkar, Suchendra and Matusik, Wojciech and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2176--2184},
  year={2016}
}

@article{hansen2009eye,
  title={In the eye of the beholder: A survey of models for eyes and gaze},
  author={Hansen, Dan Witzner and Ji, Qiang},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={32},
  number={3},
  pages={478--500},
  year={2009},
  publisher={IEEE}
}

@inproceedings{zhu2005eye,
  title={Eye gaze tracking under natural head movements},
  author={Zhu, Zhiwei and Ji, Qiang},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={1},
  pages={918--923},
  year={2005},
  organization={IEEE}
}

@inproceedings{zhu2006nonlinear,
  title={Nonlinear eye gaze mapping function estimation via support vector regression},
  author={Zhu, Zhiwei and Ji, Qiang and Bennett, Kristin P},
  booktitle={18th International Conference on Pattern Recognition (ICPR'06)},
  volume={1},
  pages={1132--1135},
  year={2006},
  organization={IEEE}
}

@article{ishikawa2004passive,
  title={Passive driver gaze tracking with active appearance models},
  author={Ishikawa, Takahiro},
  year={2004},
  publisher={figshare}
}

@inproceedings{chen20083d,
  title={3d gaze estimation with a single camera without ir illumination},
  author={Chen, Jixu and Ji, Qiang},
  booktitle={2008 19th International Conference on Pattern Recognition},
  pages={1--4},
  year={2008},
  organization={IEEE}
}

@inproceedings{yamazoe2008remote,
  title={Remote gaze estimation with a single camera based on facial-feature tracking without special calibration actions},
  author={Yamazoe, Hirotake and Utsumi, Akira and Yonezawa, Tomoko and Abe, Shinji},
  booktitle={Proceedings of the 2008 symposium on Eye tracking research \& applications},
  pages={245--250},
  year={2008},
  organization={ACM}
}

@article{valenti2011combining,
  title={Combining head pose and eye location information for gaze estimation},
  author={Valenti, Roberto and Sebe, Nicu and Gevers, Theo},
  journal={IEEE Transactions on Image Processing},
  volume={21},
  number={2},
  pages={802--815},
  year={2011},
  publisher={IEEE}
}

@inproceedings{jianfeng2014eye,
  title={Eye-model-based gaze estimation by RGB-D camera},
  author={Jianfeng, Li and Shigang, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={592--596},
  year={2014}
}

@misc{alpern1962muscular,
  title={Muscular mechanisms In H. Davson,(Ed.), The Eye. Vol. 3},
  author={Alpern, M},
  year={1962},
  publisher={New York: Academic Press}
}

@misc{Neuroscience2001,
  title={Neuroscience. 2nd edition.},
  author={Dale Purves and George J Augustine and David Fitzpatrick and Lawrence C Katz and Anthony-Samuel LaMantia and James O McNamara and S Mark Williams},
  year={2001},
  publisher={Sunderland (MA): Sinauer Associates}
}

@article{fuchs1967saccadic,
  title={Saccadic and smooth pursuit eye movements in the monkey},
  author={Fuchs, AF},
  journal={The Journal of Physiology},
  volume={191},
  number={3},
  pages={609--631},
  year={1967},
  publisher={Wiley Online Library}
}

@inproceedings{komogortsev2010qualitative,
  title={Qualitative and quantitative scoring and evaluation of the eye movement classification algorithms},
  author={Komogortsev, Oleg V and Jayarathna, Sampath and Koh, Do Hyong and Gowda, Sandeep Munikrishne},
  booktitle={Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications},
  pages={65--68},
  year={2010},
  organization={ACM}
}

@inproceedings{salvucci2000identifying,
  title={Identifying fixations and saccades in eye-tracking protocols},
  author={Salvucci, Dario D and Goldberg, Joseph H},
  booktitle={Proceedings of the 2000 symposium on Eye tracking research \& applications},
  pages={71--78},
  year={2000},
  organization={ACM}
}

@article{grasse1992analysis,
  title={Analysis of a naturally occurring asymmetry in vertical smooth pursuit eye movements in a monkey},
  author={Grasse, Keith L and Lisberger, Stephen G},
  journal={Journal of Neurophysiology},
  volume={67},
  number={1},
  pages={164--179},
  year={1992},
  publisher={American Physiological Society Bethesda, MD}
}

@inproceedings{kumar2008improving,
  title={Improving the accuracy of gaze input for interaction},
  author={Kumar, Manu and Klingner, Jeff and Puranik, Rohan and Winograd, Terry and Paepcke, Andreas},
  booktitle={Proceedings of the 2008 symposium on Eye tracking research \& applications},
  pages={65--68},
  year={2008},
  organization={ACM}
}

@article{larsson2013detection,
  title={Detection of saccades and postsaccadic oscillations in the presence of smooth pursuit},
  author={Larsson, Linn{\'e}a and Nystr{\"o}m, Marcus and Stridh, Martin},
  journal={IEEE Transactions on biomedical engineering},
  volume={60},
  number={9},
  pages={2484--2493},
  year={2013},
  publisher={IEEE}
}

@article{andersson2017one,
  title={One algorithm to rule them all? An evaluation and discussion of ten eye movement event-detection algorithms},
  author={Andersson, Richard and Larsson, Linnea and Holmqvist, Kenneth and Stridh, Martin and Nystr{\"o}m, Marcus},
  journal={Behavior research methods},
  volume={49},
  number={2},
  pages={616--637},
  year={2017},
  publisher={Springer}
}

@article{huang2017tabletgaze,
  title={TabletGaze: dataset and analysis for unconstrained appearance-based gaze estimation in mobile tablets},
  author={Huang, Qiong and Veeraraghavan, Ashok and Sabharwal, Ashutosh},
  journal={Machine Vision and Applications},
  volume={28},
  number={5-6},
  pages={445--461},
  year={2017},
  publisher={Springer}
}

@inproceedings{zhang2015appearance,
  title={Appearance-based gaze estimation in the wild},
  author={Zhang, Xucong and Sugano, Yusuke and Fritz, Mario and Bulling, Andreas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4511--4520},
  year={2015}
}

@inproceedings{morimoto2002detecting,
  title={Detecting eye position and gaze from a single camera and 2 light sources},
  author={Morimoto, Carlos Hitoshi and Amir, Arnon and Flickner, Myron},
  booktitle={Object recognition supported by user interaction for service robots},
  volume={4},
  pages={314--317},
  year={2002},
  organization={IEEE}
}

@article{shih2004novel,
  title={A novel approach to 3-D gaze tracking using stereo cameras},
  author={Shih, Sheng-Wen and Liu, Jin},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={34},
  number={1},
  pages={234--245},
  year={2004},
  publisher={IEEE}
}

@article{yoo2005novel,
  title={A novel non-intrusive eye gaze estimation using cross-ratio under large head motion},
  author={Yoo, Dong Hyun and Chung, Myung Jin},
  journal={Computer Vision and Image Understanding},
  volume={98},
  number={1},
  pages={25--51},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{hennessey2006single,
  title={A single camera eye-gaze tracking system with free head motion},
  author={Hennessey, Craig and Noureddin, Borna and Lawrence, Peter},
  booktitle={Proceedings of the 2006 symposium on Eye tracking research \& applications},
  pages={87--94},
  year={2006},
  organization={ACM}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{paszke2017automatic,
  title={Automatic Differentiation in {PyTorch}},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS Autodiff Workshop},
  year={2017}
}

@inproceedings{zhang17_cvprw,
title = {It’s Written All Over Your Face: Full-Face Appearance-Based Gaze Estimation},
author = {Xucong Zhang and Yusuke Sugano and Mario Fritz and Andreas Bulling},
url = {//wp.mpi-inf.mpg.de/perceptual/files/2017/11/zhang_cvprw2017-6.pdf
//perceptual.mpi-inf.mpg.de/research/datasets/#zhang17_cvprw},
doi = {10.1109/CVPRW.2017.284},
year = {2017},
date = {2017-05-18},
booktitle = {Proc. of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
pages = {2299-2308},
abstract = {Eye gaze is an important non-verbal cue for human affect analysis. Recent gaze estimation work indicated that information from the full face region can benefit performance. Pushing this idea further, we propose an appearance-based method that, in contrast to a long-standing line of work in computer vision, only takes the full face image as input. Our method encodes the face image using a convolutional neural network with spatial weights applied on the feature maps to flexibly suppress or enhance information in different facial regions. Through extensive evaluation, we show that our full-face method significantly outperforms the state of the art for both 2D and 3D gaze estimation, achieving improvements of up to 14.3% on MPIIGaze and 27.7% on EYEDIAP for person-independent 3D gaze estimation. We further show that this improvement is consistent across different illumination conditions and gaze directions and par- ticularly pronounced for the most challenging extreme head poses.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}

@article{zhang2017mpiigaze,
  title={Mpiigaze: Real-world dataset and deep appearance-based gaze estimation},
  author={Zhang, Xucong and Sugano, Yusuke and Fritz, Mario and Bulling, Andreas},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={41},
  number={1},
  pages={162--175},
  year={2017},
  publisher={IEEE}
}

@inproceedings{sun2013deep,
  title={Deep convolutional network cascade for facial point detection},
  author={Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3476--3483},
  year={2013}
}

@inproceedings{zhou2013extensive,
  title={Extensive facial landmark localization with coarse-to-fine convolutional network cascade},
  author={Zhou, Erjin and Fan, Haoqiang and Cao, Zhimin and Jiang, Yuning and Yin, Qi},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={386--391},
  year={2013}
}

@article{zhang2016joint,
  title={Joint face detection and alignment using multitask cascaded convolutional networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={IEEE Signal Processing Letters},
  volume={23},
  number={10},
  pages={1499--1503},
  year={2016},
  publisher={IEEE}
}

@inproceedings{chen2017delving,
  title={Delving deep into coarse-to-fine framework for facial landmark localization},
  author={Chen, Xi and Zhou, Erjin and Mo, Yuchen and Liu, Jiancheng and Cao, Zhimin},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={142--149},
  year={2017}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{iandola2016squeezenet,
  title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}

@inproceedings{zhang2019evaluation,
  title={Evaluation of Appearance-Based Methods and Implications for Gaze-Based Applications},
  author={Zhang, Xucong and Sugano, Yusuke and Bulling, Andreas},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={416},
  year={2019},
  organization={ACM}
}

@inproceedings{zhang15_cvpr,
title = {Appearance-Based Gaze Estimation in the Wild},
author = {Xucong Zhang and Yusuke Sugano and Mario Fritz and Andreas Bulling},
url = {//perceptual.mpi-inf.mpg.de/files/2015/04/zhang_CVPR15.pdf
//www.youtube.com/watch?v=rw6LZA1USG8
//perceptual.mpi-inf.mpg.de/research/datasets/#zhang15_cvpr},
doi = {10.1109/CVPR.2015.7299081},
year = {2015},
date = {2015-03-02},
booktitle = {Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2015)},
pages = {4511-4520},
abstract = {Appearance-based gaze estimation is believed to work well in real-world settings but existing datasets were collected under controlled laboratory conditions and methods were not evaluated across multiple datasets. In this work we study appearance-based gaze estimation in the wild. We present the MPIIGaze dataset that contains 213,659 images we collected from 15 participants during natural everyday laptop use over more than three months. Our dataset is significantly more variable than existing datasets with respect to appearance and illumination. We also present a method for in-the-wild appearance-based gaze estimation using multimodal convolutional neural networks, which significantly outperforms state-of-the art methods in the most challenging cross-dataset evaluation setting. We present an extensive evaluation of several state-of-the-art image-based gaze estimation algorithm on three current datasets, including our own. This evaluation provides clear insights and allows us identify key research challenges of gaze estimation in the wild.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}

@inproceedings{zhang18_etra,
title = {Revisiting Data Normalization for Appearance-Based Gaze Estimation},
author = {Xucong Zhang and Yusuke Sugano and Andreas Bulling},
url = {//perceptual.mpi-inf.mpg.de/files/2018/04/zhang18_etra.pdf
//www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/gaze-based-human-computer-interaction/revisiting-data-normalization-for-appearance-based-gaze-estimation/},
doi = {10.1145/3204493.3204548},
year = {2018},
date = {2018-03-28},
booktitle = {Proc. International Symposium on Eye Tracking Research and Applications (ETRA)},
pages = {12:1-12:9},
abstract = {Appearance-based gaze estimation is promising for unconstrained real-world settings, but the significant variability in head pose and user-camera distance poses significant challenges for training generic gaze estimators. Data normalization was proposed to cancel out this geometric variability by mapping input images and gaze labels to a normalized space. Although used successfully in prior works, the role and importance of data normalization remains unclear. To fill this gap, we study data normalization for the first time using principled evaluations on both simulated and real data. We propose a modification to the current data normalization formulation by removing the scaling factor and show that our new formulation performs significantly better (between 9.5% and 32.7%) in the different evaluation settings. Using images synthesized from a 3D face model, we demonstrate the benefit of data normalization for the efficiency of the model training. Experiments on real-world images confirm the advantages of data normalization in terms of gaze estimation performance.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}

@article{sugano2015appearance,
  title={Appearance-based gaze estimation with online calibration from mouse operations},
  author={Sugano, Yusuke and Matsushita, Yasuyuki and Sato, Yoichi and Koike, Hideki},
  journal={IEEE Transactions on Human-Machine Systems},
  volume={45},
  number={6},
  pages={750--760},
  year={2015},
  publisher={IEEE}
}

@article{lin2019eog,
  title={EOG-based eye movement classification and application on HCI baseball game},
  author={Lin, Chin-Teng and King, Juang-Tai and Bharadwaj, Priyanka and Chen, Chih-Hao and Gupta, Akshansh and Ding, Weiping and Prasad, Mukesh},
  journal={IEEE Access},
  volume={7},
  pages={96166--96176},
  year={2019},
  publisher={IEEE}
}

@inproceedings{alghowinem2013eye,
  title={Eye movement analysis for depression detection},
  author={Alghowinem, Sharifa and Goecke, Roland and Wagner, Michael and Parker, Gordon and Breakspear, Michael},
  booktitle={2013 IEEE International Conference on Image Processing},
  pages={4220--4224},
  year={2013},
  organization={IEEE}
}

@article{o1980control,
  title={The control of saccade size and fixation duration in reading: The limits of linguistic control},
  author={O’Regan, J Kevin},
  journal={Perception \& Psychophysics},
  volume={28},
  number={2},
  pages={112--117},
  year={1980},
  publisher={Springer}
}

@inproceedings{peguero2016assessing,
  title={Assessing jitter in sensor time series from Android mobile devices},
  author={Peguero, Edwin and Labrador, Miguel and Cook, Brittany},
  booktitle={2016 IEEE International Conference on Smart Computing (SMARTCOMP)},
  pages={1--8},
  year={2016},
  organization={IEEE}
}

@article{britannica1987sensory,
  title={Sensory reception: human vision: structure and function of the human eye},
  author={Britannica, Encyclopaedia},
  journal={Encyclopedia Brittanica},
  volume={27},
  pages={179},
  year={1987}
}

@inproceedings{kane2017let,
  title={Let's Talk About X: Combining Image Recognition and Eye Gaze to Support Conversation for People with ALS},
  author={Kane, Shaun K and Morris, Meredith Ringel},
  booktitle={Proceedings of the 2017 Conference on Designing Interactive Systems},
  pages={129--134},
  year={2017}
}

@inproceedings{DBLP:conf/automotiveUI/SchmidtZS19,
  author    = {Holger Schmidt and
               Gottfried Zimmermann and
               Albrecht Schmidt},
  title     = {Using gaze-based interactions in automated vehicles for increased
               road safety},
  booktitle = {Adjunct Proceedings of the 11th International Conference on Automotive
               User Interfaces and Interactive Vehicular Applications, AutomotiveUI
               2019, Utrecht, The Netherlands, September 21-25, 2019},
  pages     = {321--326},
  year      = {2019},
  crossref  = {DBLP:conf/automotiveUI/2019a},
  url       = {https://doi.org/10.1145/3349263.3351910},
  doi       = {10.1145/3349263.3351910},
  timestamp = {Mon, 23 Sep 2019 15:11:36 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/automotiveUI/SchmidtZS19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{xu2015turkergaze,
  title={Turkergaze: Crowdsourcing saliency with webcam based eye tracking},
  author={Xu, Pingmei and Ehinger, Krista A and Zhang, Yinda and Finkelstein, Adam and Kulkarni, Sanjeev R and Xiao, Jianxiong},
  journal={arXiv preprint arXiv:1504.06755},
  year={2015}
}

@book{afflerbach2015handbook,
  title={Handbook of individual differences in reading: Reader, text, and context},
  author={Afflerbach, Peter},
  year={2015},
  publisher={Routledge}
}

@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016}
}

@inproceedings{wong2019gaze,
  title={Gaze Estimation Using Residual Neural Network},
  author={Wong, En Teng and Yean, Seanglidet and Hu, Qingyao and Lee, Bu Sung and Liu, Jigang and Deepu, Rajan},
  booktitle={2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)},
  pages={411--414},
  year={2019},
  organization={IEEE}
}

@inproceedings{recasens2018learning,
  title={Learning to zoom: a saliency-based sampling layer for neural networks},
  author={Recasens, Adria and Kellnhofer, Petr and Stent, Simon and Matusik, Wojciech and Torralba, Antonio},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={51--66},
  year={2018}
}

@inproceedings{shrivastava2017learning,
  title={Learning from simulated and unsupervised images through adversarial training},
  author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2107--2116},
  year={2017}
}